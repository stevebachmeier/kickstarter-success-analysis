{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Kickstarter Project Success Analysis\n",
    "Steve Bachmeier <br>\n",
    "2018-12-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code to run for report\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Run the following two lines to hide the In[] and Out[] margin. \n",
    "# Doing so will not allow headings to be collapsed.\n",
    "\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# Run the following two lines to re-load the df_results dataframe\n",
    "import dill\n",
    "df_results = dill.load(open(\"df_results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several machine learning models were trained on a cleaned training set (60% of the entire dataset) and tested on a cleaned test set (20% of the entire dataset) - the results of these models are shown in the table below. \n",
    "\n",
    "An optimized random forest model provides a decent **10-fold cross validation mean accuracy of 71.6% while also featuring a (qualitatively) quick run-time**. \n",
    "\n",
    "The specific random forest model used features 100 trees, Gini impurity criterion, the maximum number of features to consider for a split equal to the square root of all of the features, and the minimum number of samples required to be at a leaf node of 25 (ie *n_estimators*=100, *criterion*=\"gini\", *max_features*='sqrt', and *min_samples_leaf*=25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time_fit</th>\n",
       "      <th>time_predict</th>\n",
       "      <th>time_10_fold_CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_10_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>1.53579</td>\n",
       "      <td>0.623551</td>\n",
       "      <td>0.624725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.822522</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>17.0696</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.689984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>7.340739</td>\n",
       "      <td>101.319590</td>\n",
       "      <td>344.234</td>\n",
       "      <td>0.682739</td>\n",
       "      <td>0.675807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM, Linear</td>\n",
       "      <td>954.375944</td>\n",
       "      <td>90.726687</td>\n",
       "      <td>None</td>\n",
       "      <td>0.677168</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM, RBF</td>\n",
       "      <td>1091.777649</td>\n",
       "      <td>120.427602</td>\n",
       "      <td>None</td>\n",
       "      <td>0.682908</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.437127</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>4.82765</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>0.662544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (10-fold)</td>\n",
       "      <td>1.016743</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>10.463</td>\n",
       "      <td>0.683248</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA (n=2), Naive Bayes</td>\n",
       "      <td>0.024343</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.284533</td>\n",
       "      <td>0.609355</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (Optimized)</td>\n",
       "      <td>5.856856</td>\n",
       "      <td>0.470576</td>\n",
       "      <td>66.9746</td>\n",
       "      <td>0.718257</td>\n",
       "      <td>0.716067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression (Optimized)</td>\n",
       "      <td>6.454474</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>68.8582</td>\n",
       "      <td>0.695662</td>\n",
       "      <td>0.691059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN (Optimized)</td>\n",
       "      <td>7.253727</td>\n",
       "      <td>48.397783</td>\n",
       "      <td>211.557</td>\n",
       "      <td>0.700328</td>\n",
       "      <td>0.69877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model     time_fit  time_predict  \\\n",
       "0                       Naive Bayes     0.101767      0.036270   \n",
       "1               Logistic Regression     1.822522      0.009085   \n",
       "2               K Nearest Neighbors     7.340739    101.319590   \n",
       "3                       SVM, Linear   954.375944     90.726687   \n",
       "4                          SVM, RBF  1091.777649    120.427602   \n",
       "5                     Decision Tree     0.437127      0.014542   \n",
       "6           Random Forest (10-fold)     1.016743      0.104582   \n",
       "7            PCA (n=2), Naive Bayes     0.024343      0.003595   \n",
       "8         Random Forest (Optimized)     5.856856      0.470576   \n",
       "9   Logistic Regression (Optimized)     6.454474      0.003956   \n",
       "10                  KNN (Optimized)     7.253727     48.397783   \n",
       "\n",
       "   time_10_fold_CV  accuracy acc_10_fold  \n",
       "0          1.53579  0.623551    0.624725  \n",
       "1          17.0696  0.694333    0.689984  \n",
       "2          344.234  0.682739    0.675807  \n",
       "3             None  0.677168        None  \n",
       "4             None  0.682908        None  \n",
       "5          4.82765  0.664357    0.662544  \n",
       "6           10.463  0.683248    0.680784  \n",
       "7         0.284533  0.609355    0.608927  \n",
       "8          66.9746  0.718257    0.716067  \n",
       "9          68.8582  0.695662    0.691059  \n",
       "10         211.557  0.700328     0.69877  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General trends were not so easy to recognize with the exception of the influence of the variable *staff_pick*; *staff_pick* is the predictor most highy correlated with *launch_state*:\n",
    "* *staff_pick* - *launch_state* correlation: 25%\n",
    "* 53% of projects without *staff_pick* succeed\n",
    "* 89% of projects with *staff_pick* succeed\n",
    "\n",
    "From https://www.kickstarter.com/blog/how-to-get-featured-on-kickstarter, it appears as if projects are featured when they catch the eye of the Kickstarter staff via creativity, a nice and visually appealing site, etc. ie, they are **not** just picked due to them being funded well. **Projects that are featured on Kickstarter (ie *staff_pick* = 1) have a high correlation with success, although it is difficult to tell if featured projects are already on track to be fully funded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having spent six years as a mechanical engineer in the silicon valley where ideas are big but funding is small, I've always been intrigued by the concept of crowd-funding. As an end user/backer, however, we want to maximize the chances that the projects we back actually successfully launch. This project uses historical data from the popular project-launching website Kickstarter to look for trends and make predictions about whether a project is likely to be successfully funded or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw Kickstarter data (the JSON file updated at 2018-10-18) was downloaded from: https://webrobots.io/kickstarter-datasets/. It is assumed that this data is accurate and no attempt was made to verify the web scraping tools used.\n",
    "\n",
    "Notes from raw data downloaded:\n",
    "\n",
    "* **From April 2015 we noticed that Kickstarter started limiting how many projects user can view in a single category. This limits the amount of historic projects we can get in a single scrape run. But recent and active projects are always included.**\n",
    "* **From December 2015 we modified the collection approach to go through all sub-categories instead of only top level categories. This yields more results in the datasets, but possible duplication where projects are listed in multiple categories. Also from December 2015 JSON file is in JSON streaming format. Read more about it here: https://en.wikipedia.org/wiki/JSON_Streaming**\n",
    "* **We receive many question about timestamp format used in this dataset. It is unix time. Google has a lot of information about it.**\n",
    "* **Files are compressed, size in area of 100mb. Uncompressed size around 600mb.**\n",
    "\n",
    "Note that no attempt was made for this project to ensure we have the entirety of the project history. Also, due to Github size constraints, the raw dataset is not uploaded to this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two potential goals of this project:\n",
    "\n",
    "1. Analyze the raw data obtained to look for any interesting trends.\n",
    "\n",
    "2. Build a prediction algorithm to try and predict whether future projects will successfully launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model creation\n",
    "This section outlines the analysis completed. Refer to [Appendix A1](#A1) for relevant code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to appendix [A1.1 Data preparation](#A1.1) for code.\n",
    "\n",
    "The downloaded dataset from https://webrobots.io/kickstarter-datasets/ came in JSON format; each of the 205,696 rows representing a project's details that were wrapped up in a serialized set of dictionaries and nested dictionaries. Unpacking this file was not trivial - the summary of the process is as follows:\n",
    "\n",
    "1. Open the file with utf8 encoding and load each line to a new object.\n",
    "\n",
    "2. The raw object includes four columns of dictionaries of which only the *data* column is relevant; extract that *data* column.\n",
    "\n",
    "3. Convert the json file to a Pandas dataframe.\n",
    "\n",
    "4. Unpack each dictionary with *json_normalize()*. Note that this does not unpack columns with NaN values.\n",
    "\n",
    "5. Unpack remaining dictionary columns (those with NaN values) manually by applying the Pandas *Series()* method.\n",
    "\n",
    "6. Concatenate the newly unpacked columns to the dataframe.\n",
    "\n",
    "7. Drop the original json columns from the dataframe.\n",
    "\n",
    "8. Split the dataframe into a working set (later to be the train and test set) and a validation set. We use a random 20% smapling of the entire raw dataset for the validation set.\n",
    "\n",
    "```\n",
    "X, X_v, y, y_v = train_test_split(df_raw.drop(columns=['state']), \n",
    "                                  df_raw['state'], test_size=0.2, \n",
    "                                  random_state=101)\n",
    "```\n",
    "\n",
    "The working and validation sets now consist of 97 columns (where each columns is a different variable with one of them being the outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data cleaning\n",
    "\n",
    "Refer to appendix [A1.2 Data cleaning](#A1.2) for code.\n",
    "\n",
    "With the raw data now in a usable dataframe, we can clean it up for machine learning use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Clean up columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to drop clearly useless variables. This demands some amount of reasoning. For example, it is perhaps obvious that a project photo urls, creator avatar photos, and creator profile blurbs are not useful for using machine learning to make predictions. However, other variables may not be so obvious. For example, a creator's name could be used to identify the gender (which is not provided directly in the dataset) which in turn might shed some light on project success (note that for this analysis I did indeed drop the creator's name from the dataset).\n",
    "\n",
    "One interesting variable that took special consideration is *profile_state*. Digging into it showed that there are only two unique values for *profile_state*: 'active' and 'inactive'. Further, only 11.7% of the project profiles are labeled 'active'. It is assumed that projects go 'inactive' after a certain period of latency and so cannot be used in predicting project success (ie even a successfully funded project profile may go active after some amount of time past the deadling). I decided to drop *profile_state*.\n",
    "\n",
    "Another tricky one was *usd_type*. Frankly, I was unable to get a firm grasp on what exactly it is. There were many instances of a project country being labeled, say 'US' with it's currency being 'USD' but then *usd_type* being 'international'. Further, there were instances of empty values. Finally, the vast majority of *usd_type* is labeled international. I decided to drop it.\n",
    "\n",
    "Other nonobvious variables that I deleted include: *name*, *blurb*, *loc_state* (too granular), *location_country* (largely redundant with *loc_country* but far more granular), *currency* (the pledges are all in USD), *currency_trailing_code*, and *state_changed_at*.\n",
    "\n",
    "Once the useless columns were dropped, I renamed *category_slug* to *category* and *state* to *launch_state*. \n",
    "\n",
    "Finally, I reordered the columns into a more intuitive order including putting *launch_state* first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Extract categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *category* column (initially labeled *category_slug*) included primary categories and sub-categories in the format 'primary_category/sub_category', eg 'art/painting' and 'comics/webcomics'. I simplified the *category* variable by extracting the first word, eg 'art/painting' became 'art' and 'comics/webcomics' became 'comics'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Drop duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a fair amount of duplicate rows which are easy to remove with ```df.drop_duplicates(inplace=True)```. However, even after this, the dataset included rows that were mostly duplicates with the exception of just a few column values. In order to keep the dataset tidy (where each row is a unique observation or, in this case, project), I had to remove any rows with duplicate project IDs. I decided to, in the case of duplicate IDs, keep those with the highest *pledged* value (assuming that this was input after the other rows and so is more accurate). This was accomplished with ```df = df.sort_values('pledged', ascending=False).drop_duplicates('id').sort_index()```. These two steps resulted in no duplicate ID values and so a tidy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Convert relevant values to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, *deadline* and *launched_at* contained string values that are in the unix timestamp format. These variables were converted to datetime via\n",
    "\n",
    "```\n",
    "df['deadline'] = df['deadline'].apply(datetime.utcfromtimestamp)\n",
    "df['launched_at'] = df['launched_at'].apply(datetime.utcfromtimestamp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 NA / Null / empty value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the dataframe was completely clean of any NA, Null, or empty values. This was easily checked with\n",
    "\n",
    "```\n",
    "if df.isnull().sum().sum() != 0:\n",
    "    print('*** WARNING: There are null values ***')\n",
    "if df.isna().sum().sum() != 0:\n",
    "    print('*** WARNING: There are NA values ***')\n",
    "if (df=='').sum().sum() != 0:\n",
    "    print('*** WARNING: There are empty string (\\'\\') values ***')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.6 Clean up the outcome variable *launch_state*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five values for *launch_state* (previously *state*): 'failed', 'successful', 'canceled', 'live', and 'suspended'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/launch_state.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, it makes sense to keep only 'failed' and 'successful' projects (since those labeled 'canceled' and 'suspended' cannot be backed to begin with and those labeled 'live' are exactly the projects we are trying to predict). We thus query only *launch_state* values of 'failed' and 'successful' (and type None just for completeness).\n",
    "\n",
    "```\n",
    "df.query(\"launch_state == 'failed' | \"\n",
    "         \"launch_state == 'successful' | \"\n",
    "         \"launch_state == None\", inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.7 Create dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the remaining variables, *category* and *country* are categorical, ie they are labels rather than numbers. For the machine learning algorithm, I needed to convert these to dummy variables:\n",
    "\n",
    "```\n",
    "category = pd.get_dummies(df['category'], drop_first=True)\n",
    "country = pd.get_dummies(df['country'], drop_first=True)\n",
    "```\n",
    "\n",
    "Note that I did drop the first dummy variable to ensure the correct degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.8 Convert remaining string variables to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were still several variables with categorical binary values that could be converted to binary integers.\n",
    "\n",
    "* *launch_state*: ['failed', 'successful'] should be [0, 1]\n",
    "* *staff_pick*: [False, True] should be [0, 1]\n",
    "* *spotlight*: [False, True] should be [0, 1]\n",
    "\n",
    "\n",
    "I created a dictionaries to define what the string should be converted to and then mapped it to the relevant variables.\n",
    "\n",
    "```\n",
    "d_launch_state = dict(zip(['failed','successful'], range(0,2)))\n",
    "launch_state = df['launch_state'].map(d_launch_state)\n",
    "\n",
    "d_staff_pick = dict(zip([False,True], range(0,2)))\n",
    "staff_pick = df['staff_pick'].map(d_staff_pick)\n",
    "  \n",
    "d_spotlight = dict(zip([False,True], range(0,2)))\n",
    "spotlight = df['spotlight'].map(d_spotlight)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Variable reduction\n",
    "At this point we have a tidy dataframe with 141,447 rows and 46 variables (most of which are dummy *country* and *category* variables). We can now look into paring down the number of variables to help reduce over-fitting of the machine learning algorithm(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by checking for zero variance variables, ie those variables that do not change at all throughout the entire dataset. Note that we've already removed some of these during the data cleaning phase, but it's still a good check.\n",
    "\n",
    "```\n",
    "sel = VarianceThreshold(threshold=0.0)\n",
    "sel.fit_transform(X=df.drop(columns=info_variables)).shape[1] - df.drop(columns=info_variables).shape[1]\n",
    "```\n",
    "\n",
    "There were no zero variance variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Near-zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was decided not to search for or remove near-zero variance variables. One reason is that many of the dummy variables will certainly have variances near zero, eg a particularly small *country* may only appear a hand full of times in the entire data set and so the vast majority of values will be 0. Further, there is evidence that near-zero variance variables can still have a significant impact on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Variable - outcome correlation\n",
    "<a id='3.3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables with a very high correlation to the outcome we are trying to predict should be given extra consideration and possibly dropped. For this analysis, I use a threshold correlation of 0.5 - a single variable is found as shown in the plot below. Note that the dashed red line is the threshold value.\n",
    "\n",
    "<img src=\"images/variable_outcome_correlation.jpeg\" style=\"height: 400px;\"/>\n",
    "\n",
    "It turns out that this single variable of interest is *spotlight* which, as shown in the plot, has a perfect correlation of 1 with *launch_state*. In other words, it's a perfect predictor (which obviously seems suspicious). From https://techcrunch.com/2015/03/25/kickstarter-spotlight/, we see that spotlight happens for successfully funded projects and acts as a way to update the project time line. It clearly does nothing in helping predict funding success; I dropped it.\n",
    "\n",
    "The next highest correlation is *staff_pick* at 0.25, well under the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 Variable-variable correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we consider multicollinearity, ie where a variable can be predicted by other variables. One way to battle this is by ensuring all variables have a variable-variable correlation beneath some threshold. For this analysis, we assume this threshold is 0.5.\n",
    "\n",
    "The trick here is to create an upper correlation matrix with the ones diagonal removed, unstack it, sort the values in descending order, and filter by all correlation values greater than the threshold.\n",
    "\n",
    "```\n",
    "corMat_upper = corMat.where(np.triu(np.ones(corMat.shape), k=1).astype(np.bool))\n",
    "corMat_upper.unstack().sort_values(kind='quicksort')[corMat_upper.unstack().sort_values(kind='quicksort') > .5]\n",
    "```\n",
    "\n",
    "The result is that a single variable pair has a correlation larger than 0.5:\n",
    "\n",
    "<img src=\"images/variable_variable_correlation.jpeg\" style=\"height: 400px;\"/>\n",
    "\n",
    "The variable pair in question is *US* - *GB* and has a correlation of 0.599. It does not make sense to drop a country just because it correlates with another country and so we keep both *US* and *GB* dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Exploratory data analysis\n",
    "\n",
    "Refer to appendix [A1.3 EDA](#A1.3) for code.\n",
    "\n",
    "It is always a good idea to do at least a bit of exploratory data analysis before diving into the machine learning aspect of a project. Creating visualizations can uncover interesting trends and also help guide further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairplot of all of the non-dummy variables is shown below; successful projects are green while failed are blue. There does not seem to be good separation of *launch_state* values with the exception perhaps of *goal*: it does appear as if projects with large goals have few successes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pair_plot.jpeg\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 *funding_days* vs *goal*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows *funding_days* vs *goal*; the left plot shows all data points while the right is zoomed in on the *goal* (x-) axis to $0-$250,000. We can see that while there is no significant separation at these lower goal levels, there might be a slight benefit to having longer *funding_days*. Successful launches seem loosely clustered around *funding_days* = [0,60] and *goal* < $100k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='images/funding_days_vs_goal.jpeg'></td><td><img src='images/funding_days_vs_goal_2.jpeg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 *staff_pick*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above in the [Variable - outcome correlation](#3.3.3) section, *staff_pick* has a relatively high correlation with the outcome of 0.25. Indeed, the images below show that projects chosen as a staff pick (*staff_pick* = 1) rarely fail to become successfully funded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='images/staff_pick_vs_launch_state.jpeg'></td><td><img src='images/staff_pick_vs_launch_state_2.jpeg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The bar plot below shows that the average *launch_state* for *staff_pick* of 0 and 1 is 0.523 and 0.889, respectively. Since *launch_state* is binary with 0 for failures and 1 for successes, these means also represent successful launch percentages, ie 52.3% of projects that are not chosen as a staff pick succeed while 88.9% of projects that are chosen succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/average_launch_state_vs_staff_pick.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should also be noted that 13.5% of the projects were chosen as staff picks. From https://www.kickstarter.com/blog/how-to-get-featured-on-kickstarter, it appears as if projects are featured when they catch the eye of the Kickstarter staff via creativity, a nice and visually appealing site, etc. ie, they are NOT just picked due to them being funded well.\n",
    "\n",
    "Clearly, being chosen as a staff pick is correlated with funding success. What is unclear, however, is whether getting chosen actually helps in success or if projects that were already going to be successful are chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.4 Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 main categories that a project can fall under (with hundreds of sub-categories). A frequency plot of these 15 categories is shown below. The two most common categories are 'film & video' and 'music'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/category_freq_plot.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above plot says nothing of the success of these categories. For that, I've plotted the average *launch_state* value (which, again, can be interpreted as the percentage of successes) as a function of category, below. The three most successful categories are 'comics', 'dance', and 'publishing' while the least successful are 'journalism', 'technology', and 'food'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/launch_state_vs_category_barplot.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better show that some categories have better chances of success than other, I've plotted a heatmap and a clustermap, below. Successes (*launch_state* = 1) are white and failures (*luanch_state* = 0) are black. I used 0.5 for empty cells so as not to bias towards success or failure since a project can only be one category and so most values will indeed be empty. As such, in both figures, a mostly-white column can be interpreted as a highly successful category while a mostly-black column can be interpreted as not very successful. It can be clearly seen that, as indicated above, 'journalism' and 'technology' categories have a relatively high failure rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/category_heatmap.jpeg\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/category_clustermap.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Model exploration\n",
    "\n",
    "Refer to appendix [A1.4 Model exploration](#A1.4) for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start creating the machine learning models, I separated the working dataset into train and test sets. Note that using 25% of the working set as the test size ensures that 20% of the entire raw set is reserved for the test set (this is not exact since we did some cleaning after creating the validation set, but it's close). Also note that we dropped the outcome *launch_state* variable as well as several information-only variables from the dataset to be used for machine learning variables, X.\n",
    "\n",
    "```\n",
    "info_variables = ['id','launched_at','category','country', 'pledged_ratio', 'backers_count']\n",
    "\n",
    "X = df.drop(columns=info_variables).drop(columns='launch_state')\n",
    "y = df['launch_state']\n",
    "\n",
    "#-----------------------------------------\n",
    "# TRAIN/TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=101)\n",
    "```\n",
    "\n",
    "Next, the training and test datasets were scaled.\n",
    "\n",
    "```\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "```\n",
    "\n",
    "With the data scaled, I built and analyzed all of the models of interest by\n",
    "1. loading the relevant classifier.\n",
    "2. fitting the training data and outcome vector to the classifier.\n",
    "3. predicting the test outcomes using the trained classifier on the test data.\n",
    "4. printing the confusion matrix and the classification report comparing the known test outcomes to the predicted outcomes.\n",
    "5. calculating the one-run accuracy as the sum of the confusion matrix diagonal divided by the sum of the entire confusion matrix.\n",
    "6. completing a 10-fold cross validation for models that did not take too long to run.\n",
    "7. printing the 10-fold cross validation accuracies, mean accuracy, and accuracy standard deviation.\n",
    "\n",
    "Again, all code can be found in [A1.4 Model exploration](#A1.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of these initial exploratory runs are shown in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time_fit</th>\n",
       "      <th>time_predict</th>\n",
       "      <th>time_10_fold_CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_10_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>1.53579</td>\n",
       "      <td>0.623551</td>\n",
       "      <td>0.624725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.822522</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>17.0696</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.689984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>7.340739</td>\n",
       "      <td>101.319590</td>\n",
       "      <td>344.234</td>\n",
       "      <td>0.682739</td>\n",
       "      <td>0.675807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM, Linear</td>\n",
       "      <td>954.375944</td>\n",
       "      <td>90.726687</td>\n",
       "      <td>None</td>\n",
       "      <td>0.677168</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM, RBF</td>\n",
       "      <td>1091.777649</td>\n",
       "      <td>120.427602</td>\n",
       "      <td>None</td>\n",
       "      <td>0.682908</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.437127</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>4.82765</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>0.662544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (10-fold)</td>\n",
       "      <td>1.016743</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>10.463</td>\n",
       "      <td>0.683248</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model     time_fit  time_predict time_10_fold_CV  \\\n",
       "0              Naive Bayes     0.101767      0.036270         1.53579   \n",
       "1      Logistic Regression     1.822522      0.009085         17.0696   \n",
       "2      K Nearest Neighbors     7.340739    101.319590         344.234   \n",
       "3              SVM, Linear   954.375944     90.726687            None   \n",
       "4                 SVM, RBF  1091.777649    120.427602            None   \n",
       "5            Decision Tree     0.437127      0.014542         4.82765   \n",
       "6  Random Forest (10-fold)     1.016743      0.104582          10.463   \n",
       "\n",
       "   accuracy acc_10_fold  \n",
       "0  0.623551    0.624725  \n",
       "1  0.694333    0.689984  \n",
       "2  0.682739    0.675807  \n",
       "3  0.677168        None  \n",
       "4  0.682908        None  \n",
       "5  0.664357    0.662544  \n",
       "6  0.683248    0.680784  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, all of the models seem to have similar accuracies (between ~62% and ~69%) while their run times vary greatly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look into variable reduction via principal component analysis (PCA) was then completed. The code for this is found in Appendix [A1.4.9 Principal component analysis](#A1.4.9). Fitting the training data to a PCA object with only the top two principal components results in the following scatter plot. As expected (since there was not great separation when all of the variables were included), it does not seem like reducing the variables to their principal components make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pca_2components.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, the PCA object with two principal components was fit to the Naive Bayes algorithm. It ran very fast (about 5x faster than the original Naive Bayes model) and head nearly the same accuracy (61% instead of 62%). This would be a great approach in some cases to speed things up while maintaining similar accuracy! The results table below now includes this new PCA result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time_fit</th>\n",
       "      <th>time_predict</th>\n",
       "      <th>time_10_fold_CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_10_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>1.53579</td>\n",
       "      <td>0.623551</td>\n",
       "      <td>0.624725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.822522</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>17.0696</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.689984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>7.340739</td>\n",
       "      <td>101.319590</td>\n",
       "      <td>344.234</td>\n",
       "      <td>0.682739</td>\n",
       "      <td>0.675807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM, Linear</td>\n",
       "      <td>954.375944</td>\n",
       "      <td>90.726687</td>\n",
       "      <td>None</td>\n",
       "      <td>0.677168</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM, RBF</td>\n",
       "      <td>1091.777649</td>\n",
       "      <td>120.427602</td>\n",
       "      <td>None</td>\n",
       "      <td>0.682908</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.437127</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>4.82765</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>0.662544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (10-fold)</td>\n",
       "      <td>1.016743</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>10.463</td>\n",
       "      <td>0.683248</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA (n=2), Naive Bayes</td>\n",
       "      <td>0.024343</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.284533</td>\n",
       "      <td>0.609355</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model     time_fit  time_predict time_10_fold_CV  \\\n",
       "0              Naive Bayes     0.101767      0.036270         1.53579   \n",
       "1      Logistic Regression     1.822522      0.009085         17.0696   \n",
       "2      K Nearest Neighbors     7.340739    101.319590         344.234   \n",
       "3              SVM, Linear   954.375944     90.726687            None   \n",
       "4                 SVM, RBF  1091.777649    120.427602            None   \n",
       "5            Decision Tree     0.437127      0.014542         4.82765   \n",
       "6  Random Forest (10-fold)     1.016743      0.104582          10.463   \n",
       "7   PCA (n=2), Naive Bayes     0.024343      0.003595        0.284533   \n",
       "\n",
       "   accuracy acc_10_fold  \n",
       "0  0.623551    0.624725  \n",
       "1  0.694333    0.689984  \n",
       "2  0.682739    0.675807  \n",
       "3  0.677168        None  \n",
       "4  0.682908        None  \n",
       "5  0.664357    0.662544  \n",
       "6  0.683248    0.680784  \n",
       "7  0.609355    0.608927  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model tuning and selection\n",
    "\n",
    "Refer to appendix [A1.5 Model tuning and selection](#A1.5) for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it was time to choose some models to tune and make a final selection. This was completed for three models using sklearn's *GridSearchCV* method to hone in on the parameters that optimize the results. These optimal parameters are outlined below:\n",
    "\n",
    "* Random forest:\n",
    "    * *n_estimators* = 100\n",
    "    * *criterion* = \"gini\"\n",
    "    * *max_features* = \"sqrt\"\n",
    "    * *min_samples_leaf* = 25\n",
    "\n",
    "* Logistic regression:\n",
    "    * *C* = 10\n",
    "    * *penalty* = \"l1\"\n",
    "\n",
    "* K nearest neighbors:\n",
    "    * *metric* = \"minkowski\"\n",
    "    * *n_neighbors* = 23\n",
    "    * *p* = 2\n",
    "\n",
    "We also plotted validation curves for the numeric parameters to double-check for over-fitting. These curves are shown below (**Note: The image of the KNN validation curve was unortunately not saved before the entire session was pickled and dumped, ie I do not have that particular plot**). Note that they agree with the above outline; the models are made complicated enough to minimize variance but not so complicated that bias becomes unnecessarily large. Interestingly, the training and cross-validation curves do not start deviating from each other (high bias) when the random forest mode's *n_neighbors* is high which is what I would expect from an over-fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='images/validation_curves_random_forest.jpeg'></td><td><img src='images/validation_curves_logistic_regression.jpeg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three models with optimized parameters were then run and results appended to the results table as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time_fit</th>\n",
       "      <th>time_predict</th>\n",
       "      <th>time_10_fold_CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_10_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.036270</td>\n",
       "      <td>1.53579</td>\n",
       "      <td>0.623551</td>\n",
       "      <td>0.624725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.822522</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>17.0696</td>\n",
       "      <td>0.694333</td>\n",
       "      <td>0.689984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>7.340739</td>\n",
       "      <td>101.319590</td>\n",
       "      <td>344.234</td>\n",
       "      <td>0.682739</td>\n",
       "      <td>0.675807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM, Linear</td>\n",
       "      <td>954.375944</td>\n",
       "      <td>90.726687</td>\n",
       "      <td>None</td>\n",
       "      <td>0.677168</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM, RBF</td>\n",
       "      <td>1091.777649</td>\n",
       "      <td>120.427602</td>\n",
       "      <td>None</td>\n",
       "      <td>0.682908</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.437127</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>4.82765</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>0.662544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (10-fold)</td>\n",
       "      <td>1.016743</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>10.463</td>\n",
       "      <td>0.683248</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA (n=2), Naive Bayes</td>\n",
       "      <td>0.024343</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.284533</td>\n",
       "      <td>0.609355</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (Optimized)</td>\n",
       "      <td>5.856856</td>\n",
       "      <td>0.470576</td>\n",
       "      <td>66.9746</td>\n",
       "      <td>0.718257</td>\n",
       "      <td>0.716067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression (Optimized)</td>\n",
       "      <td>6.454474</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>68.8582</td>\n",
       "      <td>0.695662</td>\n",
       "      <td>0.691059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN (Optimized)</td>\n",
       "      <td>7.253727</td>\n",
       "      <td>48.397783</td>\n",
       "      <td>211.557</td>\n",
       "      <td>0.700328</td>\n",
       "      <td>0.69877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model     time_fit  time_predict  \\\n",
       "0                       Naive Bayes     0.101767      0.036270   \n",
       "1               Logistic Regression     1.822522      0.009085   \n",
       "2               K Nearest Neighbors     7.340739    101.319590   \n",
       "3                       SVM, Linear   954.375944     90.726687   \n",
       "4                          SVM, RBF  1091.777649    120.427602   \n",
       "5                     Decision Tree     0.437127      0.014542   \n",
       "6           Random Forest (10-fold)     1.016743      0.104582   \n",
       "7            PCA (n=2), Naive Bayes     0.024343      0.003595   \n",
       "8         Random Forest (Optimized)     5.856856      0.470576   \n",
       "9   Logistic Regression (Optimized)     6.454474      0.003956   \n",
       "10                  KNN (Optimized)     7.253727     48.397783   \n",
       "\n",
       "   time_10_fold_CV  accuracy acc_10_fold  \n",
       "0          1.53579  0.623551    0.624725  \n",
       "1          17.0696  0.694333    0.689984  \n",
       "2          344.234  0.682739    0.675807  \n",
       "3             None  0.677168        None  \n",
       "4             None  0.682908        None  \n",
       "5          4.82765  0.664357    0.662544  \n",
       "6           10.463  0.683248    0.680784  \n",
       "7         0.284533  0.609355    0.608927  \n",
       "8          66.9746  0.718257    0.716067  \n",
       "9          68.8582  0.695662    0.691059  \n",
       "10         211.557  0.700328     0.69877  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the prediction accuracy increases slightly for all three models when using optimized parameters. An optimized random forest model provides the best accuracy at ~72% while at the same time remaining efficient and fast to run. This is the chosen model for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Prediction / final validation\n",
    "\n",
    "Refer to appendix [A2 Code - new data prediction](#A2) for relevant code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one specific model chosen to launch, it is time for a final validation. In this case, this validation also serves as a proving grounds for the final product. Recall that thus far we have not touched 20% of the initial raw data - this untouched set was set aside as a validation set. Keeping a completely separated validation set is useful because it ensures that the model in no way relied on it. This is in contrast to the training set which was used extensively to fit and train the model. Even the test set was used indirectly to baseline the model when doing accuracy comparisons. Only the validation set has been 100% unused.\n",
    "\n",
    "The goal here is to then create a script that takes in raw Kickstarter project data (again, in this case that raw data is the validation set previously set aside), cleans it up, and uses the chosen machine learning algorithm to predict which projects will be successfully funded or not. Since we do have the real-life outcomes of this set, we can also calculate our final product accuracy.\n",
    "\n",
    "Aside from some extra code that asks the user for input, runs various handling exceptions, and deals with whether or not the input file is a truly raw JSON file or whether it is an extracted dataframe from the JSON file (as is the case here with the validation set), the product script is quite simple. It \n",
    "\n",
    "1. takes in the raw data.\n",
    "2. cleans the data.\n",
    "3. extracts the relevant machine learning columns as well as the outcome column (if one exists).\n",
    "4. applies the prediction algorithm.\n",
    "5. writes out the prediction vector to a CSV file.\n",
    "6. evaluates the accuracy of the prediction vector to the known values, if applicable. Specifically, it prints the confusion matrix, classification report, and calculates the accuracy as the sum of the confusion matrix diagonal divided by the sum of the entire confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the script is quite simple. \n",
    "1. Ensure that Python is properly installed.\n",
    "2. Ensure that the following files are located in the working directly:\n",
    "\t* classifier_rf_opt.pkl\n",
    "\t* f_cleanData.py\n",
    "\t* f_dataImport.py\n",
    "\t* f_predict.py\n",
    "\t* predict.py\n",
    "\t* sc_X.pkl\n",
    "3. Create a folder named 'data' in the working directory.\n",
    "4. Download or create the Kickstarter data to run the prediction model on.\n",
    "\t* The data must be in JSON format like from https://webrobots.io/kickstarter-datasets/.\n",
    "\t* Alternatively, the data can a comma-separated value dataframe from previously-run analyses.\n",
    "5. Save the raw data in the 'data' folder.\n",
    "6. Open a command prompt.\n",
    "7. Type 'python predict.py'\n",
    "8. Follow the prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A screen shot of this process is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/validation_cmd.jpg\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image also shows the confusion matrix, classification report, and calculated accuracy. As expected, **the model performs admirably with a 70% accuracy and managed to complete the analysis in only 1.49 seconds**. Further, a copy of the prediction vector was saved in the home folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Next steps\n",
    "\n",
    "Some recommendations to improve this analysis include:\n",
    "\n",
    "* Complete an analysis to determine the statistical influence of the 'staff_pick' variable, ie while it appears as if staff_pick = 1 results in a higher chance that a project is successfully funded, is this statistically accurate?\n",
    "* Re-run the analysis without the country dummy variables.\n",
    "* Re-run the analysis without the category dummy variables.\n",
    "* Code the finished script so that it can accept raw data without every column. Specifically, a small enough amount of raw data may not include all of the required countries or categories currently required to fit the model.\n",
    "* Analyze the effect of including sub-categories in the analysis.\n",
    "* Look for trends in the failed predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "<a id='Appendix'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Code - model creation\n",
    "<a id='A1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.1 Data preparation function (as of 2018-12-12)\n",
    "<a id='A1.1'></a>\n",
    "\n",
    "**Relevant file: 'f_dataImport.py'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 27 14:06:31 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# IMPORT LIBRARIES\n",
    "#\n",
    "#==============================================================================\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.io.json import json_normalize \n",
    "import json\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# FUNCTION - RAW DATA IMPORT\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "def dataImport():\n",
    "    '''\n",
    "    This function imports the raw json data downloaded from \n",
    "    https://webrobots.io/kickstarter-datasets/ and extracts the dictionaries\n",
    "    into a usable dataframe format.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        * 'df_raw.csv': raw data dataframe\n",
    "    '''\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # READ IN RAW DATA\n",
    "    \n",
    "    print('\\n')\n",
    "    print('***')\n",
    "    print('NOTE:')\n",
    "    print('The input file must be JSON with the same format as those'\n",
    "          'downloaded from https://webrobots.io/kickstarter-datasets/')\n",
    "    print('***')\n",
    "        \n",
    "    while True:\n",
    "    \n",
    "        print('\\n')\n",
    "        new_data = str(input('Input the new data JSON filepath you want to predict: '))\n",
    "        \n",
    "        if not os.path.exists(new_data):\n",
    "            print('\\n')\n",
    "            print('The filepath \\'', new_data, '\\' does not exist.', sep='')\n",
    "            continue\n",
    "        else:\n",
    "            print('\\n')\n",
    "            yesno = str(input(f'Confirm that \\'{new_data}\\' is the correct '\n",
    "                              'filepath (\\'y\\' or \\'n\\'): '))\n",
    "            \n",
    "            if (yesno[0].lower() == \"y\"):\n",
    "                with open(new_data, encoding=\"utf8\") as json_file:\n",
    "                     json_obj = [json.loads(line) for line in json_file]\n",
    "                break\n",
    "            elif (yesno[0].lower() == 'n'):\n",
    "                print('\\n')\n",
    "                continue\n",
    "            else:\n",
    "                print('\\n')\n",
    "                print('Improper input')\n",
    "                continue\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # UNPACK RAW DATA\n",
    "    \n",
    "    json_obj2 = []\n",
    "    # append 'data' dictionary only\n",
    "    for x in range(0, len(json_obj)):\n",
    "        json_obj2.append(json_obj[x][\"data\"])\n",
    "    \n",
    "    # Check\n",
    "    if (len(json_obj2) - len(json_obj)) != 0:\n",
    "        print('*** ERROR: Did not extract all json \\'data\\' entries ***')\n",
    "\n",
    "    # ---- CONVERT TO DATAFRAME ----\n",
    "    df_raw_json = pd.DataFrame(json_obj2)\n",
    "    \n",
    "    # ---- UNPACK DICTIONARY ENTRIES ----\n",
    "    # 'category'\n",
    "    df_category = json_normalize(data=df_raw_json['category'])\n",
    "    df_category.columns = 'category_' + df_category.columns\n",
    "    \n",
    "    # 'creator'\n",
    "    df_creator = json_normalize(data=df_raw_json['creator'])\n",
    "    df_creator.columns = 'creator_' + df_creator.columns\n",
    "    \n",
    "    # 'location'\n",
    "    # Must mannually unpack 'location' with pd.Series due to NaN elements\n",
    "    df_location = df_raw_json['location'].apply(pd.Series)\n",
    "    df_location.drop(columns=0, inplace=True)\n",
    "    df_location.columns = 'location_'+df_location.columns\n",
    "    df_location1 = df_location['location_urls'].apply(pd.Series)\n",
    "    df_location1.drop(columns=0, inplace=True)\n",
    "    df_location1.columns = 'location_urls_'+df_location1.columns\n",
    "    df_location2 = df_location1['location_urls_web'].apply(pd.Series)\n",
    "    df_location2.drop(columns=0, inplace=True)\n",
    "    df_location2.columns = 'location_urls_web_'+df_location2.columns\n",
    "    df_location3 = df_location1['location_urls_api'].apply(pd.Series)\n",
    "    df_location3.drop(columns=0, inplace=True)\n",
    "    df_location3.columns = 'location_urls_api_'+df_location3.columns\n",
    "    # Concat 'location' dataframes\n",
    "    df_location = pd.concat([df_location, df_location2, df_location3], axis=1)\n",
    "    df_location.drop(columns='location_urls', inplace=True)\n",
    "    \n",
    "    # 'photo'\n",
    "    df_photo = json_normalize(data=df_raw_json['photo'])\n",
    "    df_photo.columns = 'photo_' + df_photo.columns\n",
    "    \n",
    "    # 'profile'\n",
    "    df_profile = json_normalize(data=df_raw_json['profile'])\n",
    "    df_profile.columns = 'profile_' + df_profile.columns\n",
    "    \n",
    "    # 'urls'\n",
    "    df_urls = json_normalize(data=df_raw_json['urls'])\n",
    "    df_urls.columns = 'urls_' + df_urls.columns\n",
    "     \n",
    "    # ---- CONCAT UNPACKED DATAFRAMES ----\n",
    "    df_raw = pd.concat([df_raw_json, df_category, df_creator, df_location, \n",
    "                        df_photo, df_profile, df_urls], axis=1)\n",
    "    df_raw.drop(columns=['category','creator','location','photo',\n",
    "                         'profile','urls'], inplace=True)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # WRITE OUT\n",
    "    \n",
    "    df_raw.to_csv('data/df_raw.csv', sep=\",\")\n",
    "    \n",
    "    return df_raw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### A1.2 Data cleaning function (as of 2018-12-12)\n",
    "<a id='A1.2'></a>\n",
    "\n",
    "**Relevant file: 'f_cleanData.py'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 10 13:04:33 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# IMPORT LIBRARIES\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# FUNCTION - CLEAN DATA\n",
    "#\n",
    "#==============================================================================\n",
    "def cleanData(df):\n",
    "    '''\n",
    "    This function cleans downloaded raw data for the Kickstarter success \n",
    "    prediction project. The input dataframe must be imported and the json \n",
    "    extracted using '00 - Data Import.py'. There should be either 95 or 96\n",
    "    columns (the 'state' column is optional) and they must be labeled exactly\n",
    "    as defined in '00 - Data Import.py'.\n",
    "    '''\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # ADD EMPTY STATE COLUMN IF NECESSARY\n",
    "    if 'state' not in df.columns:\n",
    "        df['state'] = None\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # COLUMN CLEANUP\n",
    "    \n",
    "    drop_vars = ['photo_1024x576', 'photo_1536x864', 'photo_ed', 'photo_full', \n",
    "                 'photo_key', 'photo_little', 'photo_med', 'photo_small', \n",
    "                 'photo_thumb', 'slug', 'urls_api.message_creator', 'urls_api.star', \n",
    "                 'urls_web.message_creator', 'urls_web.project', 'urls_web.rewards', \n",
    "                 'source_url', 'creator_avatar.medium', 'creator_avatar.small', \n",
    "                 'creator_avatar.thumb', 'creator_chosen_currency', 'creator_id', \n",
    "                 'creator_name', 'creator_slug', 'creator_urls.api.user',\n",
    "                 'creator_urls.web.user', 'location_id', 'location_name', \n",
    "                 'location_slug', 'location_short_name', 'location_displayable_name', \n",
    "                 'location_localized_name', 'location_type', 'location_is_root', \n",
    "                 'location_urls_web_discover', 'location_urls_web_location', \n",
    "                 'location_urls_api_nearby_projects', 'category_color', \n",
    "                 'category_id', 'category_urls.web.discover', \n",
    "                 'profile_background_color', \n",
    "                 'profile_background_image_attributes.id', \n",
    "                 'profile_background_image_attributes.image_urls.baseball_card', \n",
    "                 'profile_background_image_attributes.image_urls.default',\n",
    "                 'profile_background_image_opacity', 'profile_blurb', \n",
    "                 'profile_feature_image_attributes.id', \n",
    "                 'profile_feature_image_attributes.image_urls.baseball_card',\n",
    "                 'profile_feature_image_attributes.image_urls.default', 'profile_id',\n",
    "                 'profile_link_background_color', 'profile_link_text', \n",
    "                 'profile_link_text_color', 'profile_link_url', 'profile_name', \n",
    "                 'profile_project_id', 'profile_should_show_feature_image_section', \n",
    "                 'profile_show_feature_image', 'profile_state', \n",
    "                 'profile_state_changed_at', 'profile_text_color', 'currency_symbol',\n",
    "                 'static_usd_rate','converted_pledged_amount','fx_rate',\n",
    "                 'current_currency', 'usd_pledged', 'is_starrable', 'friends', \n",
    "                 'is_backing', 'is_starred', 'permissions', 'name', 'blurb',\n",
    "                 'location_state', 'location_country', 'currency', \n",
    "                 'currency_trailing_code', 'state_changed_at', 'category_parent_id', \n",
    "                 'category_position', 'category_name', 'category_id', \n",
    "                 'creator_is_registered', 'disable_communication', 'created_at', \n",
    "                 'usd_type']\n",
    "\n",
    "    df.drop(columns=drop_vars, inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    df.rename(columns={'category_slug':'category', 'state':'launch_state'}, inplace=True)\n",
    "    \n",
    "    # Rearrange columns\n",
    "    df = df[['launch_state', 'id', 'category', 'goal', 'backers_count', \n",
    "             'pledged', 'country','deadline', 'launched_at', \n",
    "             'staff_pick', 'spotlight']]\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # EXTRACT CATEGORIES\n",
    "    df['category'] = [i.split('/')[0] for i in df['category']]\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # REMOVE DUPLICATES\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # For duplicate IDs leftover, remove the lesser pledged row\n",
    "    df = df.sort_values('pledged', ascending=False).drop_duplicates('id').sort_index()\n",
    "    \n",
    "    # Check\n",
    "    if (len(df) - len(df[\"id\"])) != 0:\n",
    "        print('*** WARNING: There are ',\n",
    "              len(df) - len(df[\"id\"]), \n",
    "              ' duplicate IDs ***', sep='')\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # CONVERT DATETIMES\n",
    "    df['deadline'] = df['deadline'].apply(datetime.utcfromtimestamp)\n",
    "    df['launched_at'] = df['launched_at'].apply(datetime.utcfromtimestamp)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # NA IMPUTATION \n",
    "    # Checks\n",
    "    if df.isnull().sum().sum() != 0:\n",
    "        print('*** WARNING: There are null values ***')\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        print('*** WARNING: There are NA values ***')\n",
    "    if (df=='').sum().sum() != 0:\n",
    "        print('*** WARNING: There are empty string (\\'\\') values ***')\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # CLEAN UP 'launch_state'\n",
    "    df.query(\"launch_state == 'failed' | \"\n",
    "             \"launch_state == 'successful' | \"\n",
    "             \"launch_state == None\", inplace=True)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # CONVERT CATEGORICAL VARIABLES TO DUMMY VARIABLES \n",
    "    category = pd.get_dummies(df['category'], drop_first=True)\n",
    "    country = pd.get_dummies(df['country'], drop_first=True)\n",
    "    d_launch_state = dict(zip(['failed','successful'], range(0,2)))\n",
    "    launch_state = df['launch_state'].map(d_launch_state)\n",
    "    \n",
    "    # Check\n",
    "    if (df[df['launch_state'] == 'successful'].shape[0] - launch_state.sum() != 0):\n",
    "        print('*** WARNING: Some launch_states did not map to 0/1 ***')\n",
    "    \n",
    "    # Drop the categorical launch_state column \n",
    "    # (keep 'category' and 'country' for  visualization)\n",
    "    df.drop(['launch_state'],axis=1,inplace=True)\n",
    "    \n",
    "    # Add the new dummy variable launch_state column and move it to column index 0 \n",
    "    # and country to column index 3\n",
    "    df = pd.concat([launch_state, df], axis=1)\n",
    "    df = df[['launch_state', 'id', 'category', 'country', 'goal', 'backers_count', \n",
    "             'pledged','deadline', 'launched_at', 'staff_pick', 'spotlight']]\n",
    "    \n",
    "    # Add the dummy variable country and category columns\n",
    "    df = pd.concat([df, category, country], axis=1)\n",
    "    \n",
    "    # Checks\n",
    "    if (df.isnull().sum().sum() != 0):\n",
    "        print('*** WARNING: Null values introduced with dummy variables ***')\n",
    "    if (df.isna().sum().sum() != 0):\n",
    "        print('*** WARNING: NA values introduced with dummy variables ***')\n",
    "    if (df=='').sum().sum() != 0:\n",
    "        print('*** WARNING: Empty string (\\'\\') values introduced with dummy variables ***')\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # FINAL CLEANUP\n",
    "    # pledged_ratio\n",
    "    pledged_ratio = df['pledged'] / df['goal']\n",
    "    df.insert(loc=df.columns.get_loc(\"pledged\"), column='pledged_ratio', \n",
    "              value=pledged_ratio)\n",
    "    df.drop(columns='pledged', inplace=True)\n",
    "    \n",
    "    # datetime columns\n",
    "    funding_days = (df['deadline'] - df['launched_at']).dt.days\n",
    "    df.insert(loc=df.columns.get_loc(\"deadline\"), column='funding_days', \n",
    "              value=funding_days)\n",
    "    df.drop(columns='deadline', inplace=True)\n",
    "    \n",
    "    # ---- MOVE 'LAUNCHED_AT' ----\n",
    "    launched_at = df['launched_at']\n",
    "    df.drop(columns='launched_at', inplace=True)\n",
    "    df.insert(loc=2, column='launched_at', value=launched_at)\n",
    "    \n",
    "    # ---- CONVERT 'STAFF_PICK' AND 'SPOTLIGHT' TO DUMMIES ----\n",
    "    d_staff_pick = dict(zip([False,True], range(0,2)))\n",
    "    staff_pick = df['staff_pick'].map(d_staff_pick)\n",
    "    \n",
    "    # Check\n",
    "    if (df[df['staff_pick'] == True].shape[0] - staff_pick.sum()) != 0:\n",
    "        print('*** WARNING: \\'staff_pick\\' not mapped to 0/1 properly ***')\n",
    "        \n",
    "    d_spotlight = dict(zip([False,True], range(0,2)))\n",
    "    spotlight = df['spotlight'].map(d_spotlight)\n",
    "    \n",
    "    # Check\n",
    "    if (df[df['spotlight'] == True].shape[0] - spotlight.sum()) != 0:\n",
    "        print('*** WARNING: \\'spotlight\\' not mapped to 0/1 properly ***')\n",
    "        \n",
    "    df.drop(['staff_pick','spotlight'],axis=1,inplace=True)\n",
    "    \n",
    "    df.insert(loc=df.columns.get_loc(\"comics\"), column='staff_pick', value=staff_pick)\n",
    "    df.insert(loc=df.columns.get_loc(\"comics\"), column='spotlight', value=spotlight)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # VARIABLE REDUCTION\n",
    "    df.drop(columns='spotlight', inplace=True)\n",
    "    \n",
    "    # ---- NULL/NA/EMPTY CHECKS ----\n",
    "    if (df.isnull().sum().sum() != 0):\n",
    "        print('*** WARNING: Null values introduced with \\'staff_pick\\' and \\'spotlight\\' dummy variables ***')\n",
    "    if (df.isna().sum().sum() != 0):\n",
    "        print('*** WARNING: NA values introduced with \\'staff_pick\\' and \\'spotlight\\' dummy variables ***')\n",
    "    if (df=='').sum().sum() != 0:\n",
    "        print('*** WARNING: Empty string (\\'\\') values introduced with \\'staff_pick\\' and \\'spotlight\\' dummy variables ***')\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # WRITE OUT\n",
    "    df.to_csv('df_clean.csv', sep=\",\")\n",
    "    \n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### A1.3 EDA (as of 2018-12-12)\n",
    "<a id='A1.3'></a>\n",
    "\n",
    "**Relevant file: '03 - EDA.py'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 15 14:43:36 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "\n",
    "#-----------------------------------------\n",
    "# USER INPUTS\n",
    "\n",
    "\n",
    "#-----------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#-----------------------------------------\n",
    "# IMPORT DATAFRAME\n",
    "\n",
    "df = pd.read_csv('data/df02.csv', sep=',', na_filter=False, index_col=0, \n",
    "                 parse_dates=['launched_at'])\n",
    "\n",
    "# Checks\n",
    "if (df.isnull().sum().sum() != 0):\n",
    "    print('*** WARNING: Null values introduced with read_csv ***')\n",
    "if (df.isna().sum().sum() != 0):\n",
    "    print('*** WARNING: NA values introduced with read_csv ***')\n",
    "if (df=='').sum().sum() != 0:\n",
    "    print('*** WARNING: Empty string (\\'\\') values introduced with read_csv ***')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "# ---- EXPLORE launch_state ----\n",
    "fig=plt.figure(figsize=(8,4))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='launch_state', data=df, palette='viridis')\n",
    "\n",
    "# Success rate is proving difficult to calculate due to dirty (especially\n",
    "# duplicate data. TBD)\n",
    "\n",
    "# =============================================================================\n",
    "# It looks like a huge portion of projects ultimately fail to launch! We will\n",
    "# look into this more later, but for now consider the following from \n",
    "# https://www.kickstarter.com/help/stats (as of 2018-11-16 10:40):\n",
    "#  * Overall success rate: 36.53%\n",
    "#      - Why is this different than the 53.2% success rate calculted above?\n",
    "#  * \"While 13% of projects finished having never received a single pledge 78%\n",
    "#    of projects that raised more than 20% of their goal were successfully \n",
    "#    funded.\"\n",
    "# =============================================================================\n",
    "\n",
    "# ---- DUMMY VARIABLE PAIRPLOT ----\n",
    "sns.set_context(\"paper\", rc={\"axes.labelsize\":20, \n",
    "                             \"xtick.labelsize\": 15, \"ytick.labelsize\": 15})\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.pairplot(data=df.drop(df.columns[10:], axis=1).drop(\n",
    "        columns=['id','launched_at','category','country']), \n",
    "             diag_kind='kde', hue='launch_state', palette='viridis')\n",
    "# Observation: little insight to be gained here\n",
    "\n",
    "# ---- FUNDING_DAYS VS GOAL ----\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"funding_days\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"funding_days\", data=df, hue='launch_state', size=12,palette='viridis',\n",
    "           fit_reg=False, scatter_kws={'alpha':0.5, 's':500}).set(xlim=(0,250000))\n",
    "\n",
    "# =============================================================================\n",
    "# Observations: \n",
    "#  * Successful launches seem loosely clustered around funding_days = [0,60]\n",
    "#    and goal < $100k\n",
    "# =============================================================================\n",
    "\n",
    "# ---- BACKERS_COUNT VS GOAL ----\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"backers_count\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"backers_count\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis').set(\n",
    "    xlim=(0,250000), ylim=(0,15000))\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"backers_count\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis').set(\n",
    "    xlim=(0,100000), ylim=(0,2000))\n",
    "\n",
    "# =============================================================================\n",
    "# Observations: backers_count is not a good predictor; it's obvious that\n",
    "# with a high number of backers the project is more likely to succeed. More\n",
    "# important for this project, though, is the fact that it cannot be used a priori.\n",
    "# =============================================================================\n",
    "\n",
    "# ---- PLEDGED_RATIO vs GOAL ----\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"pledged_ratio\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"pledged_ratio\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, \n",
    "           palette='viridis').set(xlim=(0,250000), ylim=(0,2))\n",
    "\n",
    "# =============================================================================\n",
    "# Observations: As expected, pledged_ratio < 1 means failure and all\n",
    "# pledged_ratio >= 1 means success\n",
    "# =============================================================================\n",
    "\n",
    "# ---- STAFF_PICK vs GOAL ----\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"staff_pick\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500}, palette='viridis')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=3)\n",
    "sns.lmplot(\"goal\", \"staff_pick\", data=df, hue='launch_state', size=12,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.1, 's':500},\n",
    "           palette='viridis').set(xlim=(0,250000))\n",
    "\n",
    "# Observations: Staff_pick seems to be a decent indicator in launch_state\n",
    "\n",
    "# ---- EXPLORE STAFF_PICK AND LAUNCH_STATE\n",
    "df_staff_picks = df[['launch_state','staff_pick']].groupby(\n",
    "        ['staff_pick'], as_index=False).count()\n",
    "df_staff_picks.columns = ['staff_pick','freq']\n",
    "df_staff_picks['ratio'] = df[['launch_state','staff_pick']].groupby(\n",
    "        ['staff_pick'], as_index=False).mean()['launch_state']\n",
    "\n",
    "plt.figure()\n",
    "sns.set_style('whitegrid')\n",
    "ax = sns.barplot(data = df[['launch_state','staff_pick']].groupby(\n",
    "        ['staff_pick'], as_index=False).mean(), x='staff_pick', y='launch_state')\n",
    "ax.set(xlabel='staff_pick', ylabel='Average launch_state')\n",
    "\n",
    "# =============================================================================\n",
    "# Observations: \n",
    "#   * 13.5% of projects are chosen as staff picks\n",
    "#   * staff_pick seems to correlate with launch_state:\n",
    "#     - 52.3% of projects not chosen as staff picks succeed\n",
    "#     - 88.9% of projects chosen as staff picks succeed \n",
    "#\n",
    "# From https://www.kickstarter.com/blog/how-to-get-featured-on-kickstarter,\n",
    "# it appears as if projects are featured when they catch the eye of the\n",
    "# Kickstarter staff via creativity, a nice and visually appealing site, etc. \n",
    "# ie, they are NOT just picked due to them being funded well.\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# So what have we learned so far?\n",
    "# * goal - use it\n",
    "# * backers_count - do not use it (it's not known beforehand)\n",
    "# * pledged_ratio - do not use it (it's just an indicator of success)\n",
    "# * funding_days - use it\n",
    "# * staff_pick - use it\n",
    "# =============================================================================\n",
    "\n",
    "# ---- VISUALIZE CATEGORIES ----\n",
    "df_categories = df[['launch_state','category']].groupby(\n",
    "        [\"category\"]).describe().reset_index()\n",
    "df_categories.sort_values(by=[('launch_state','mean')], ascending=False)\n",
    "print(df_categories)\n",
    "\n",
    "# Frequency plot\n",
    "sns.set_style('whitegrid')\n",
    "sns.factorplot(x='category', data=df, kind='count', size=10)\n",
    "\n",
    "# Success ratio plot\n",
    "plt.figure()\n",
    "sns.set_style('whitegrid')\n",
    "sns.barplot(x='category',y='launch_state',data=df)\n",
    "\n",
    "# Observations: clearly, some categories are more successful than others.\n",
    "\n",
    "# Heatmap\n",
    "# Note that I fill in empty cells with 0.5 so as not to bias towards\n",
    "# 0 (failure) and 1 (success)\n",
    "plt.figure()\n",
    "sns.set_style('whitegrid')\n",
    "ax = sns.heatmap(\n",
    "        df.pivot_table(values='launch_state', columns='category', \n",
    "                       index='funding_days', fill_value=0.5), xticklabels=True)\n",
    "ax.invert_yaxis()\n",
    "plt.title('Heatmap, launch_state - category vs funding_days')\n",
    "\n",
    "# Clustermap\n",
    "sns.set_style('whitegrid')\n",
    "sns.clustermap(df.pivot_table(values='launch_state', columns='category', \n",
    "                              index='funding_days', fill_value=0.5),\n",
    "                xticklabels=True)\n",
    "plt.title('Clustermap, launch_state - category vs funding_days')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id='A1.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### A1.4 Model exploration (as of 2018-12-12)\n",
    "<a id='A1.4'></a>\n",
    "\n",
    "**Relevant file:  '04 Working - Models.ipynb'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.1 Model setup\n",
    "<a id='A1.4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#-----------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "pd.options.display.max_columns = None # Shows all columns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#-----------------------------------------\n",
    "# DUMP/LOAD SESSIONS\n",
    "\n",
    "import dill\n",
    "\n",
    "# ---- FULL SESSIONS ----\n",
    "#dill.dump_session('./04 Working - Models.db')\n",
    "#dill.load_session('./04 Working - Models.db')\n",
    "\n",
    "# ---- OBJECTS ----\n",
    "#dill.dump(sc_X, open(\"sc_X.pkl\", \"wb\"))\n",
    "#dill.dump(classifier_rf_opt, open(\"classifier_rf_opt.pkl\", \"wb\"))\n",
    "#dill.dump(df_results, open(\"df_results.pkl\", \"wb\"))\n",
    "\n",
    "#-----------------------------------------\n",
    "# IMPORT DATAFRAME\n",
    "\n",
    "df = pd.read_csv('data/df02.csv', sep=',', na_filter=False, index_col=0, \n",
    "                 parse_dates=['launched_at'])\n",
    "\n",
    "# Checks\n",
    "if (df.isnull().sum().sum() != 0):\n",
    "    print('*** WARNING: Null values introduced with read_csv ***')\n",
    "if (df.isna().sum().sum() != 0):\n",
    "    print('*** WARNING: NA values introduced with read_csv ***')\n",
    "if (df=='').sum().sum() != 0:\n",
    "    print('*** WARNING: Empty string (\\'\\') values introduced with read_csv ***')\n",
    "    \n",
    "info_variables = ['id','launched_at','category','country', 'pledged_ratio', 'backers_count']\n",
    "\n",
    "X = df.drop(columns=info_variables).drop(columns='launch_state')\n",
    "y = df['launch_state']\n",
    "\n",
    "#-----------------------------------------\n",
    "# TRAIN/TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=101)\n",
    "    \n",
    "#-----------------------------------------\n",
    "# FEATURE SCALING\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.2 Naive Bayes\n",
    "<a id='A1.4.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# NAIVE BAYES\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Naive-Bayes\n",
    "classifier_nb = GaussianNB()\n",
    "classifier_nb.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_nb = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_nb, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_nb = classifier_nb.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_nb = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_nb, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "# Classification report\n",
    "cr_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(cm_nb)\n",
    "print(\"\\n\")\n",
    "print(cr_nb)\n",
    "\n",
    "acc_nb = cm_nb.diagonal().sum() / cm_nb.sum()\n",
    "acc_nb\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_nb = cross_val_score(\n",
    "    estimator=classifier_nb, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_nb = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_nb, 2), ' sec', sep='')\n",
    "\n",
    "print(\"Accuracies:\")\n",
    "print(accuracies_nb)\n",
    "print('\\n')\n",
    "print(\"RESULTS:\")\n",
    "print(f\"  - Mean accuracy: {round(accuracies_nb.mean(), 2)*100}%\")\n",
    "print(f\"  - Accuracy std dev: {round(accuracies_nb.std(), 2)*100}%\")\n",
    "\n",
    "df_results_nb = pd.DataFrame([{\n",
    "    'model':'Naive Bayes', \n",
    "    'time_fit':clock_fit_nb, 'time_predict':clock_predict_nb,\n",
    "    'time_10_fold_CV':clock_10FCV_nb,\n",
    "    'accuracy':acc_nb, 'acc_10_fold':accuracies_nb.mean()}])\n",
    "    \n",
    "df_results_nb = df_results_nb[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "df_results = df_results_nb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.3 Logistic regression\n",
    "<a id='A1.4.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# LOGISTIC REGRESSION\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Logistic regression\n",
    "classifier_LogReg = LogisticRegression(random_state=101)\n",
    "classifier_LogReg.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_LogReg = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_LogReg, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_LogReg = classifier_LogReg.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_LogReg = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_LogReg, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_LogReg = confusion_matrix(y_test, y_pred_LogReg)\n",
    "\n",
    "# Classification report\n",
    "cr_LogReg = classification_report(y_test, y_pred_LogReg)\n",
    "\n",
    "print(cm_LogReg)\n",
    "print(\"\\n\")\n",
    "print(cr_LogReg)\n",
    "\n",
    "acc_LogReg = cm_LogReg.diagonal().sum() / cm_LogReg.sum()\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_LogReg = cross_val_score(\n",
    "    estimator=classifier_LogReg, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_LogReg = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_LogReg, 2), ' sec', sep='')\n",
    "\n",
    "print(\"Accuracies:\")\n",
    "print(accuracies_LogReg)\n",
    "print('\\n')\n",
    "print(\"RESULTS:\")\n",
    "print(f\"  - Mean accuracy: {round(accuracies_LogReg.mean(), 2)*100}%\")\n",
    "print(f\"  - Accuracy std dev: {round(accuracies_LogReg.std(), 2)*100}%\")\n",
    "\n",
    "df_results_LogReg = pd.DataFrame([{\n",
    "    'model':'Logistic Regression', \n",
    "    'time_fit':clock_fit_LogReg, 'time_predict':clock_predict_LogReg,\n",
    "    'time_10_fold_CV':clock_10FCV_LogReg,\n",
    "    'accuracy':acc_LogReg, 'acc_10_fold':accuracies_LogReg.mean()}])\n",
    "df_results_LogReg = df_results_LogReg[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_LogReg).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.4 K nearest neighbors\n",
    "<a id='A1.4.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# K NEAREST NEIGHBORS\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# KNN\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)\n",
    "classifier_knn.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_knn = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_knn, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_knn = classifier_knn.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_knn = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_knn, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Classification report\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "print(cm_knn)\n",
    "print(\"\\n\")\n",
    "print(cr_knn)\n",
    "\n",
    "acc_knn = cm_knn.diagonal().sum() / cm_knn.sum()\n",
    "acc_knn\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_knn + clock_predict_knn)*10/60, 2), \n",
    "      ' min')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_knn = cross_val_score(\n",
    "    estimator=classifier_knn, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_knn = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_knn, 2), ' sec', sep='')\n",
    "\n",
    "print(\"Accuracies:\")\n",
    "print(accuracies_knn)\n",
    "print('\\n')\n",
    "print(\"RESULTS:\")\n",
    "print(f\"  - Mean accuracy: {round(accuracies_knn.mean(), 2)*100}%\")\n",
    "print(f\"  - Accuracy std dev: {round(accuracies_knn.std(), 2)*100}%\")\n",
    "\n",
    "df_results_knn = pd.DataFrame([{\n",
    "    'model':'K Nearest Neighbors', \n",
    "    'time_fit':clock_fit_knn, 'time_predict':clock_predict_knn,\n",
    "    'time_10_fold_CV':clock_10FCV_knn,\n",
    "    'accuracy':acc_knn, 'acc_10_fold':accuracies_knn.mean()}])\n",
    "df_results_knn = df_results_knn[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_knn).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.5 Support vector machine\n",
    "<a id='A1.4.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# SUPPORT VECTOR MACHINE\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# SVM\n",
    "classifier_svm_linear = SVC(kernel=\"linear\", random_state=101)\n",
    "classifier_svm_linear.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_svm_linear = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_svm_linear, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_svm_linear = classifier_svm_linear.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_svm_linear = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_svm_linear, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_svm_linear = confusion_matrix(y_test, y_pred_svm_linear)\n",
    "\n",
    "# Classification report\n",
    "cr_svm_linear = classification_report(y_test, y_pred_svm_linear)\n",
    "\n",
    "print(cm_svm_linear)\n",
    "print(\"\\n\")\n",
    "print(cr_svm_linear)\n",
    "\n",
    "acc_svm_linear = cm_svm_linear.diagonal().sum() / cm_svm_linear.sum()\n",
    "acc_svm_linear\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_svm_linear + clock_predict_svm_linear)*10/60/60, 2), \n",
    "      ' hours')\n",
    "      \n",
    "# *** TIME-INTENSIVE ***\n",
    "\"\"\"start_clock = time.clock()\n",
    "\n",
    "accuracies_svm = cross_val_score(\n",
    "    estimator=classifier_svm, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_svm = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_svm, 2), ' sec', sep='')\"\"\"\n",
    "\n",
    "try:\n",
    "    clock_10FCV_svm_linear\n",
    "except:\n",
    "    clock_10FCV_svm_linear = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_svm_linear\n",
    "except:\n",
    "    accuracy_10FCV_mean_svm_linear = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_svm_linear = accuracies_svm_linear.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_svm_linear)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_svm_linear.mean(),4)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_svm_linear.std(),4)*100}%\")\n",
    "    \n",
    "df_results_svm_linear = pd.DataFrame([{\n",
    "    'model':'SVM, Linear', \n",
    "    'time_fit':clock_fit_svm_linear, 'time_predict':clock_predict_svm_linear,\n",
    "    'time_10_fold_CV':clock_10FCV_svm_linear,\n",
    "    'accuracy':acc_svm_linear, 'acc_10_fold':accuracy_10FCV_mean_svm_linear}])\n",
    "df_results_svm_linear = df_results_svm_linear[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_svm_linear).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.6 Support vector machine, kernel RBF\n",
    "<a id='A1.4.6'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "============================================================================\n",
    "#\n",
    "# SUPPORT VECTOR MACHINE, KERNEL RBF\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# SVM\n",
    "classifier_svm_rbf = SVC(kernel=\"rbf\", random_state=101)\n",
    "classifier_svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_svm_rbf = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_svm_rbf, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_svm_rbf = classifier_svm_rbf.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_svm_rbf = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_svm_rbf, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_svm_rbf = confusion_matrix(y_test, y_pred_svm_rbf)\n",
    "\n",
    "# Classification report\n",
    "cr_svm_rbf = classification_report(y_test, y_pred_svm_rbf)\n",
    "\n",
    "print(cm_svm_rbf)\n",
    "print(\"\\n\")\n",
    "print(cr_svm_rbf)\n",
    "\n",
    "acc_svm_rbf = cm_svm_rbf.diagonal().sum() / cm_svm_rbf.sum()\n",
    "acc_svm_rbf\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_svm_rbf + clock_predict_svm_rbf)*10/60/60, 2), \n",
    "      ' hours')\n",
    "      \n",
    "# *** TIME-INTENSIVE ***\n",
    "\"\"\"start_clock = time.clock()\n",
    "\n",
    "accuracies_svm_rbf = cross_val_score(\n",
    "    estimator=classifier_svm_rbf, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_svm_rbf = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_svm_rbf, 2), ' sec', sep='')\"\"\"\n",
    "\n",
    "try:\n",
    "    clock_10FCV_svm_rbf\n",
    "except:\n",
    "    clock_10FCV_svm_rbf = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_svm_rbf\n",
    "except:\n",
    "    accuracy_10FCV_mean_svm_rbf = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_svm_rbf = accuracies_svm_rbf.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_svm_rbf)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_svm_rbf.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_svm_rbf.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_svm_rbf = pd.DataFrame([{\n",
    "    'model':'SVM, RBF', \n",
    "    'time_fit':clock_fit_svm_rbf, 'time_predict':clock_predict_svm_rbf,\n",
    "    'time_10_fold_CV':clock_10FCV_svm_rbf,\n",
    "    'accuracy':acc_svm_rbf, 'acc_10_fold':accuracy_10FCV_mean_svm_rbf}])\n",
    "df_results_svm_rbf = df_results_svm_rbf[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_svm_rbf).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.7 Decision tree\n",
    "<a id='A1.4.7'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# DECISION TREE CLASSIFICATION\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Decision tree\n",
    "classifier_dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=101)\n",
    "classifier_dt.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_dt = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_dt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_dt = classifier_dt.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_dt = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_dt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "# Classification report\n",
    "cr_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(cm_dt)\n",
    "print(\"\\n\")\n",
    "print(cr_dt)\n",
    "\n",
    "acc_dt = cm_dt.diagonal().sum() / cm_dt.sum()\n",
    "acc_dt\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_dt + clock_predict_dt)*10, 2), \n",
    "      ' sec')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_dt = cross_val_score(\n",
    "    estimator=classifier_dt, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_dt = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_dt, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_dt\n",
    "except:\n",
    "    clock_10FCV_dt = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_dt\n",
    "except:\n",
    "    accuracy_10FCV_mean_dt = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_dt = accuracies_dt.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_dt)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_dt.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_dt.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_dt = pd.DataFrame([{\n",
    "    'model':'Decision Tree', \n",
    "    'time_fit':clock_fit_dt, 'time_predict':clock_predict_dt,\n",
    "    'time_10_fold_CV':clock_10FCV_dt,\n",
    "    'accuracy':acc_dt, 'acc_10_fold':accuracy_10FCV_mean_dt}])\n",
    "df_results_dt = df_results_dt[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_dt).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.8 Random forest, 10-fold\n",
    "<a id='A1.4.8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# RANDOM FOREST CLASSIFICATION (10 fold)\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Decision tree\n",
    "classifier_rf10 = RandomForestClassifier(n_estimators=10, criterion=\"entropy\", random_state=101)\n",
    "classifier_rf10.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_rf10 = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_rf10, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_rf10 = classifier_rf10.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_rf10 = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_rf10, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rf10 = confusion_matrix(y_test, y_pred_rf10)\n",
    "\n",
    "# Classification report\n",
    "cr_rf10 = classification_report(y_test, y_pred_rf10)\n",
    "\n",
    "print(cm_rf10)\n",
    "print(\"\\n\")\n",
    "print(cr_rf10)\n",
    "\n",
    "acc_rf10 = cm_rf10.diagonal().sum() / cm_rf10.sum()\n",
    "acc_rf10\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_rf10 + clock_predict_rf10)*10, 2), \n",
    "      ' sec')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_rf10 = cross_val_score(\n",
    "    estimator=classifier_rf10, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_rf10 = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_rf10, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_rf10\n",
    "except:\n",
    "    clock_10FCV_rf10 = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_rf10\n",
    "except:\n",
    "    accuracy_10FCV_mean_rf10 = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_rf10 = accuracies_rf10.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_rf10)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_rf10.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_rf10.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_rf10 = pd.DataFrame([{\n",
    "    'model':'Random Forest (10-fold)', \n",
    "    'time_fit':clock_fit_rf10, 'time_predict':clock_predict_rf10,\n",
    "    'time_10_fold_CV':clock_10FCV_rf10,\n",
    "    'accuracy':acc_rf10, 'acc_10_fold':accuracy_10FCV_mean_rf10}])\n",
    "df_results_rf10 = df_results_rf10[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_rf10).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A1.4.9 Principal component analysis\n",
    "<a id='A1.4.9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# PRINCIPAL COMPONENT ANALYSIS\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "# Explore principal components\n",
    "pca = PCA(n_components=None, random_state=101)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "explained_variance_pca = pca.explained_variance_ratio_\n",
    "\n",
    "print(explained_variance_pca)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_train_pca[:,0], X_train_pca[:,1], c=y_train, cmap='plasma')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "# Explore top two principal components\n",
    "pca = PCA(n_components=2, random_state=101)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "explained_variance_pca = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_train_pca[:,0], X_train_pca[:,1], c=y_train, cmap='plasma')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL (NAIVE BAYES)\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Naive-Bayes\n",
    "classifier_pca2_nb = GaussianNB()\n",
    "classifier_pca2_nb.fit(X_train_pca, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_pca2_nb = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_pca2_nb, 2), ' sec', sep='')\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_pca2_nb = classifier_pca2_nb.predict(X_test_pca)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_pca2_nb = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_pca2_nb, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_pca2_nb = confusion_matrix(y_test, y_pred_pca2_nb)\n",
    "\n",
    "# Classification report\n",
    "cr_pca2_nb = classification_report(y_test, y_pred_pca2_nb)\n",
    "\n",
    "print(cm_pca2_nb)\n",
    "print(\"\\n\")\n",
    "print(cr_pca2_nb)\n",
    "\n",
    "acc_pca2_nb = cm_pca2_nb.diagonal().sum() / cm_pca2_nb.sum()\n",
    "acc_pca2_nb\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_pca2_nb = cross_val_score(\n",
    "    estimator=classifier_pca2_nb, X=X_train_pca, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_pca2_nb = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_pca2_nb, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_pca2_nb\n",
    "except:\n",
    "    clock_10FCV_pca2_nb = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_pca2_nb\n",
    "except:\n",
    "    accuracy_10FCV_mean_pca2_nb = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_pca2_nb = accuracies_pca2_nb.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_pca2_nb)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_pca2_nb.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_pca2_nb.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_pca2_nb = pd.DataFrame([{\n",
    "    'model':'PCA (n=2), Naive Bayes', \n",
    "    'time_fit':clock_fit_pca2_nb, 'time_predict':clock_predict_pca2_nb,\n",
    "    'time_10_fold_CV':clock_10FCV_pca2_nb,\n",
    "    'accuracy':acc_pca2_nb, 'acc_10_fold':accuracy_10FCV_mean_pca2_nb}])\n",
    "df_results_pca2_nb = df_results_pca2_nb[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_pca2_nb).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.5 Model tuning and selection (as of 2018-12-12)\n",
    "<a id='A1.5'></a>\n",
    " \n",
    "**Relevant file:  '04 Working - Models.ipynb'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### A1.5.1 Grid search - random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# GRID SEARCH - RANDOM FOREST\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "# FIT MODEL\n",
    "classifier_grid_rf = RandomForestClassifier(random_state=101)\n",
    "\n",
    "# Decide parameters to loop through\n",
    "parameters_rf = {\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'n_estimators': [1,5,10,20,30,50,75,100],\n",
    "    'min_samples_leaf': [1,2,5,10,25,50,100],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Create validation curve objects\n",
    "param_range = np.arange(1,110,10)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(random_state=101), X_train, y_train, param_name='n_estimators', \n",
    "    param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot validation curve\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "#plt.ylim(0.68, 0.72)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_rf = GridSearchCV(estimator=classifier_grid_rf,\n",
    "    param_grid=parameters_rf, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "    \n",
    "# Fit grid search object to training set\n",
    "\n",
    "start_clock = time.clock()\n",
    "grid_search_rf = grid_search_rf.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_grid_search_rf = end_clock - start_clock\n",
    "\n",
    "print('Runtime, grid search: ', round(clock_grid_search_rf, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_rf = grid_search_rf.best_score_\n",
    "best_parameters_grid_search_rf = grid_search_rf.best_params_\n",
    "print(f\"Best accuracy: {round(best_accuracy_grid_search_rf, 2)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Best parameters: {best_parameters_grid_search_rf}\")\n",
    "\n",
    "# Search again\n",
    "\n",
    "# Decide parameters to loop through\n",
    "parameters_rf = {\n",
    "    'max_features': ['sqrt'],\n",
    "    'n_estimators': [100,200,300],\n",
    "    'min_samples_leaf': [15,20,25,30,35,40,45],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_rf = GridSearchCV(estimator=classifier_grid_rf,\n",
    "    param_grid=parameters_rf, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "\n",
    "# Fit grid search object to training set\n",
    "start_clock = time.clock()\n",
    "grid_search_rf = grid_search_rf.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "clock_grid_search_rf = end_clock - start_clock\n",
    "print('Runtime, grid search: ', round(clock_grid_search_rf, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_rf = grid_search_rf.best_score_\n",
    "best_parameters_grid_search_rf = grid_search_rf.best_params_\n",
    "print(f\"Best accuracy: {round(best_accuracy_grid_search_rf, 2)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Best parameters: {best_parameters_grid_search_rf}\")\n",
    "\n",
    "# Search again\n",
    "\n",
    "# Decide parameters to loop through\n",
    "parameters_rf = {\n",
    "    'max_features': ['sqrt'],\n",
    "    'n_estimators': [90,100,110],\n",
    "    'min_samples_leaf': [21,23,25,27,29],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_rf = GridSearchCV(estimator=classifier_grid_rf,\n",
    "    param_grid=parameters_rf, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "\n",
    "# Fit grid search object to training set\n",
    "start_clock = time.clock()\n",
    "grid_search_rf = grid_search_rf.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "clock_grid_search_rf = end_clock - start_clock\n",
    "print('Runtime, grid search: ', round(clock_grid_search_rf, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_rf = grid_search_rf.best_score_\n",
    "best_parameters_grid_search_rf = grid_search_rf.best_params_\n",
    "print(f\"Best accuracy: {round(best_accuracy_grid_search_rf, 2)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Best parameters: {best_parameters_grid_search_rf}\")\n",
    "\n",
    "# ---- RUN WITH OPTIMIZED PARAMETERS ----\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "# Decision tree\n",
    "classifier_rf_opt = RandomForestClassifier(\n",
    "    n_estimators=100, criterion=\"gini\", max_features='sqrt', min_samples_leaf=25, random_state=101)\n",
    "classifier_rf_opt.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_rf_opt = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_rf_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_rf_opt = classifier_rf_opt.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_rf_opt = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_rf_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rf_opt = confusion_matrix(y_test, y_pred_rf_opt)\n",
    "\n",
    "# Classification report\n",
    "cr_rf_opt = classification_report(y_test, y_pred_rf_opt)\n",
    "\n",
    "print(cm_rf_opt)\n",
    "print(\"\\n\")\n",
    "print(cr_rf_opt)\n",
    "\n",
    "acc_rf_opt = cm_rf_opt.diagonal().sum() / cm_rf_opt.sum()\n",
    "acc_rf_opt\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_rf_opt + clock_predict_rf_opt)*10, 2), \n",
    "      ' sec')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_rf_opt = cross_val_score(\n",
    "    estimator=classifier_rf_opt, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_rf_opt = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_rf_opt, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_rf_opt\n",
    "except:\n",
    "    clock_10FCV_rf_opt = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_rf_opt\n",
    "except:\n",
    "    accuracy_10FCV_mean_rf_opt = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_rf_opt = accuracies_rf_opt.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_rf_opt)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_rf_opt.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_rf_opt.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_rf_opt = pd.DataFrame([{\n",
    "    'model':'Random Forest (Optimized)', \n",
    "    'time_fit':clock_fit_rf_opt, 'time_predict':clock_predict_rf_opt,\n",
    "    'time_10_fold_CV':clock_10FCV_rf_opt,\n",
    "    'accuracy':acc_rf_opt, 'acc_10_fold':accuracy_10FCV_mean_rf_opt}])\n",
    "df_results_rf_opt = df_results_rf_opt[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_rf_opt).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### A1.5.2 Grid search - logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# GRID SEARCH - LOGISTIC REGRESSION\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "# FIT MODEL\n",
    "classifier_grid_LogReg = LogisticRegression(random_state=101)\n",
    "\n",
    "# Decide parameters to loop through\n",
    "param_range = np.logspace(0,3,10)\n",
    "parameters_LogReg = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': param_range\n",
    "}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_LogReg = GridSearchCV(estimator=classifier_grid_LogReg,\n",
    "    param_grid=parameters_LogReg, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "    \n",
    "# Create validation curve objects\n",
    "train_scores, test_scores = validation_curve(\n",
    "    LogisticRegression(random_state=101), X_train, y_train, param_name='C', \n",
    "    param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot validation curve\n",
    "plt.title(\"Validation Curve with Logistic Regression\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.68, 0.70)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# Fit grid search object to training set\n",
    "\n",
    "start_clock = time.clock()\n",
    "grid_search_LogReg = grid_search_LogReg.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_grid_search_LogReg = end_clock - start_clock\n",
    "\n",
    "print('Runtime, grid search: ', round(clock_grid_search_LogReg, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_LogReg = grid_search_LogReg.best_score_\n",
    "best_parameters_grid_search_LogReg = grid_search_LogReg.best_params_\n",
    "print(f\"Best accuracy: {round(best_accuracy_grid_search_LogReg, 2)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Best parameters: {best_parameters_grid_search_LogReg}\")\n",
    "\n",
    "# Search again\n",
    "\n",
    "# Decide parameters to loop through\n",
    "parameters_LogReg = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': np.logspace(0.5,2,19)\n",
    "}\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_LogReg = GridSearchCV(estimator=classifier_grid_LogReg,\n",
    "    param_grid=parameters_LogReg, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "\n",
    "# Fit grid search object to training set\n",
    "start_clock = time.clock()\n",
    "grid_search_LogReg = grid_search_LogReg.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "clock_grid_search_LogReg = end_clock - start_clock\n",
    "print('Runtime, grid search: ', round(clock_grid_search_LogReg, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_LogReg = grid_search_LogReg.best_score_\n",
    "best_parameters_grid_search_LogReg = grid_search_LogReg.best_params_\n",
    "print(f\"Best accuracy: {round(best_accuracy_grid_search_LogReg, 2)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Best parameters: {best_parameters_grid_search_LogReg}\")\n",
    "\n",
    "# ---- RUN WITH OPTIMIZED PARAMETERS ----\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "classifier_LogReg_opt = LogisticRegression(random_state=101, C=10.0, penalty='l1')\n",
    "classifier_LogReg_opt.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_LogReg_opt = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_LogReg_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_LogReg_opt = classifier_LogReg_opt.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_LogReg_opt = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_LogReg_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_LogReg_opt = confusion_matrix(y_test, y_pred_LogReg_opt)\n",
    "\n",
    "# Classification report\n",
    "cr_LogReg_opt = classification_report(y_test, y_pred_LogReg_opt)\n",
    "\n",
    "print(cm_LogReg_opt)\n",
    "print(\"\\n\")\n",
    "print(cr_LogReg_opt)\n",
    "\n",
    "acc_LogReg_opt = cm_LogReg_opt.diagonal().sum() / cm_LogReg_opt.sum()\n",
    "acc_LogReg_opt\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimated time: ', \n",
    "      round((clock_fit_LogReg_opt + clock_predict_LogReg_opt)*10, 2), \n",
    "      ' sec')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_LogReg_opt = cross_val_score(\n",
    "    estimator=classifier_LogReg_opt, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_LogReg_opt = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_LogReg_opt, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_LogReg_opt\n",
    "except:\n",
    "    clock_10FCV_LogReg_opt = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    \n",
    "try:\n",
    "    accuracies_LogReg_opt\n",
    "except:\n",
    "    accuracy_10FCV_mean_LogReg_opt = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_LogReg_opt = accuracies_LogReg_opt.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_LogReg_opt)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"  - Mean accuracy: {round(accuracies_LogReg_opt.mean(), 2)*100}%\")\n",
    "    print(f\"  - Accuracy std dev: {round(accuracies_LogReg_opt.std(), 2)*100}%\")\n",
    "    \n",
    "df_results_LogReg_opt = pd.DataFrame([{\n",
    "    'model':'Logistic Regression (Optimized)', \n",
    "    'time_fit':clock_fit_LogReg_opt, 'time_predict':clock_predict_LogReg_opt,\n",
    "    'time_10_fold_CV':clock_10FCV_LogReg_opt,\n",
    "    'accuracy':acc_LogReg_opt, 'acc_10_fold':accuracy_10FCV_mean_LogReg_opt}])\n",
    "df_results_LogReg_opt = df_results_LogReg_opt[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_LogReg_opt).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A1.5.3 Grid search - K nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#==============================================================================\n",
    "#\n",
    "# GRID SEARCH - K NEAREST NEIGHBORS\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "classifier_grid_knn = KNeighborsClassifier()\n",
    "\n",
    "# Decide parameters to loop through\n",
    "param_range = np.arange(1,25,1)\n",
    "parameters_knn = {\n",
    "    'n_neighbors': param_range,\n",
    "    'metric': ['minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create validation curve objects\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KNeighborsClassifier(), X_train, y_train, param_name='n_neighbors', \n",
    "    param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot validation curve\n",
    "plt.title(\"Validation Curve with K Nearest Neighbors\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "#plt.ylim(0.68, 0.72)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# Create grid search object\n",
    "grid_search_knn = GridSearchCV(estimator=classifier_grid_knn,\n",
    "    param_grid=parameters_knn, scoring=\"accuracy\", cv=5,\n",
    "    n_jobs=-1, verbose=10)\n",
    "    \n",
    "# Fit grid search object to training set\n",
    "\n",
    "start_clock = time.clock()\n",
    "grid_search_knn = grid_search_knn.fit(X_train, y_train)\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_grid_search_knn = end_clock - start_clock\n",
    "\n",
    "print('Runtime, grid search: ', round(clock_grid_search_knn, 2), ' sec', sep='')\n",
    "\n",
    "# Print results\n",
    "best_accuracy_grid_search_knn = grid_search_knn.best_score_\n",
    "best_parameters_grid_search_knn = grid_search_knn.best_params_\n",
    "print(\"Best accuracy: \", round(best_accuracy_grid_search_knn, 2)*100, \"%\", sep=\"\")\n",
    "print(\"\\n\")\n",
    "print(\"Best parameters: \", best_parameters_grid_search_knn, sep=\"\")\n",
    "\n",
    "# ---- RUN WITH OPTIMIZED PARAMETERS ----\n",
    "\n",
    "#-----------------------------------------\n",
    "# FIT MODEL\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "classifier_knn_opt = KNeighborsClassifier(metric='minkowski', n_neighbors=23, p=2, n_jobs=-1)\n",
    "classifier_knn_opt.fit(X_train, y_train)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_fit_knn_opt = end_clock - start_clock\n",
    "print('Runtime, fit: ', round(clock_fit_knn_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# PREDICT TEST RESULTS\n",
    "\n",
    "start_clock = time.clock()\n",
    "\n",
    "y_pred_knn_opt = classifier_knn_opt.predict(X_test)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_predict_knn_opt = end_clock - start_clock\n",
    "print('Runtime, predict: ', round(clock_predict_knn_opt, 2), ' sec', sep='')\n",
    "\n",
    "#-----------------------------------------\n",
    "# EVALUATE MODEL\n",
    "\n",
    "# Confusion matrix\n",
    "cm_knn_opt = confusion_matrix(y_test, y_pred_knn_opt)\n",
    "\n",
    "# Classification report\n",
    "cr_knn_opt = classification_report(y_test, y_pred_knn_opt)\n",
    "\n",
    "print(cm_knn_opt)\n",
    "print(\"\\n\")\n",
    "print(cr_knn_opt)\n",
    "\n",
    "acc_knn_opt = cm_knn_opt.diagonal().sum() / cm_knn_opt.sum()\n",
    "acc_knn_opt\n",
    "\n",
    "#-----------------------------------------\n",
    "# APPLY K-FOLD CROSS VALIDATION\n",
    "\n",
    "# 10-fold cross validation time estimate:\n",
    "print('10-fold CV estimatknnd time: ', \n",
    "      round((clock_fit_knn_opt + clock_predict_knn_opt)*10, 2), \n",
    "      ' sec')\n",
    "      \n",
    "start_clock = time.clock()\n",
    "\n",
    "accuracies_knn_opt = cross_val_score(\n",
    "    estimator=classifier_knn_opt, X=X_train, y=y_train,\n",
    "    cv=10)\n",
    "\n",
    "end_clock = time.clock()\n",
    "\n",
    "clock_10FCV_knn_opt = end_clock - start_clock\n",
    "print('Runtime, 10-fold CV: ', round(clock_10FCV_knn_opt, 2), ' sec', sep='')\n",
    "\n",
    "try:\n",
    "    clock_10FCV_knn_opt\n",
    "except:\n",
    "    clock_10FCV_knn_opt = None\n",
    "    print(\"No 10-fold CV time to report\")\n",
    "    try:\n",
    "    accuracies_knn_opt\n",
    "except:\n",
    "    accuracy_10FCV_mean_knn_opt = None\n",
    "    print(\"No K-fold CV accuracies to report\")\n",
    "else:\n",
    "    accuracy_10FCV_mean_knn_opt = accuracies_knn_opt.mean()\n",
    "    print(\"Accuracies:\")\n",
    "    print(accuracies_knn_opt)\n",
    "    print('\\n')\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"  - Mean accuracy: \", round(accuracies_knn_opt.mean(), 2)*100, \"%\", sep=\"\")\n",
    "    print(\"  - Accuracy std dev: \", round(accuracies_knn_opt.std(), 2)*100, \"%\", sep=\"\")\n",
    "    \n",
    "df_results_knn_opt = pd.DataFrame([{\n",
    "    'model':'KNN (Optimized)', \n",
    "    'time_fit':clock_fit_knn_opt, 'time_predict':clock_predict_knn_opt,\n",
    "    'time_10_fold_CV':clock_10FCV_knn_opt,\n",
    "    'accuracy':acc_knn_opt, 'acc_10_fold':accuracy_10FCV_mean_knn_opt}])\n",
    "df_results_knn_opt = df_results_knn_opt[['model','time_fit','time_predict','time_10_fold_CV','accuracy','acc_10_fold']]\n",
    "\n",
    "df_results = pd.DataFrame.append(df_results, df_results_knn_opt).reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A2 Code - new data prediction\n",
    "<a id='A2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A2.1 Predict function\n",
    "<a id='A2.1'></a>\n",
    "\n",
    "**Relevant file: 'f_predict.py'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 10 14:25:31 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "    \n",
    "#==============================================================================\n",
    "#\n",
    "# IMPORT LIBRARIES\n",
    "#\n",
    "#==============================================================================\n",
    "import dill\n",
    "import time\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# PICKLING\n",
    "#\n",
    "#==============================================================================\n",
    "sc_X = dill.load(open(\"sc_X.pkl\", \"rb\"))\n",
    "classifier_rf_opt = dill.load(open(\"classifier_rf_opt.pkl\", \"rb\"))\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# FUNCTION - PREDICT\n",
    "#\n",
    "#==============================================================================\n",
    "def predictLaunchState(X):\n",
    "    '''\n",
    "    This function accepts a new data dataframe and uses a chosen machine \n",
    "    learning model to predict whether each observation will be successfully\n",
    "    funded ('launch_state' = 1) or not ('launch_state' = 0).\n",
    "    '''\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # X/y SPLIT\n",
    "    \n",
    "    info_variables = ['id','launched_at','category','country', \n",
    "                      'pledged_ratio', 'backers_count']\n",
    "    X = X.drop(columns=info_variables)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # SCALE FEATURES\n",
    "    X = sc_X.transform(X)   \n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # PREDICT RESULTS\n",
    "    \n",
    "    start_clock = time.clock()\n",
    "    y_pred = classifier_rf_opt.predict(X)\n",
    "    end_clock = time.clock()\n",
    "    \n",
    "    clock_predict = end_clock - start_clock\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Runtime, predict: ', round(clock_predict, 2), ' sec', sep='')\n",
    "    \n",
    "    return y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A2.2 Final prediction script\n",
    "<a id='A2.2'></a>\n",
    "\n",
    "**Relevant file: 'predict.py'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 10 16:49:34 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# IMPORT LIBRARIES\n",
    "#\n",
    "#==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from f_dataImport import dataImport\n",
    "from f_cleanData import cleanData\n",
    "from f_predict import predictLaunchState\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# RAW DATA IMPORT\n",
    "#\n",
    "#==============================================================================\n",
    "            \n",
    "while True:\n",
    "    print('\\n')\n",
    "    try:\n",
    "        choice = int(input('What sort of raw data do you have? (Enter 1 or 2): \\n'\n",
    "                           '  [1] JSON data  \\n'\n",
    "                           '  [2] Dataframe from previously cleaned raw JSON file: '))\n",
    "    except:\n",
    "        print('\\n')\n",
    "        print('Input an integer (1 or 2)')\n",
    "        continue\n",
    "    else:\n",
    "        if (choice == 1):\n",
    "            df = dataImport()\n",
    "            break\n",
    "        elif (choice == 2):\n",
    "            print('\\n')\n",
    "            new_data = str(input('Input the new dataframe filepath you want to predict: '))\n",
    "        \n",
    "            if not os.path.exists(new_data):\n",
    "                print('\\n')\n",
    "                print('The filepath \\'', new_data, '\\' does not exist.', sep='')\n",
    "                continue\n",
    "            else:\n",
    "                print('\\n')\n",
    "                yesno = str(input(f'Confirm that \\'{new_data}\\' is the correct '\n",
    "                                  'filepath (\\'y\\' or \\'n\\'): '))\n",
    "                \n",
    "                if (yesno[0].lower() == \"y\"):\n",
    "                    df = pd.read_csv(new_data, sep=',', na_filter=False, index_col=0)  \n",
    "                    break\n",
    "                elif (yesno[0].lower() == 'n'):\n",
    "                    print('\\n')\n",
    "                    continue\n",
    "                else:\n",
    "                    print('\\n')\n",
    "                    print('Improper input')\n",
    "                    continue\n",
    "            break\n",
    "        else:\n",
    "            print('\\n')\n",
    "            print('Must input 1 or 2')\n",
    "            continue\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# CLEAN DATA\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "df = cleanData(df)\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# EXTRACT OUTCOME\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "X = df.drop(columns = 'launch_state')\n",
    "y = df['launch_state']\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# PREDICT\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "y_pred = predictLaunchState(X)\n",
    "\n",
    "#-----------------------------------------\n",
    "# WRITE OUT PREDICTIONS\n",
    "np.savetxt('y_pred.csv', y_pred, delimiter=',')\n",
    "\n",
    "#==============================================================================\n",
    "#\n",
    "# EVALUATE IF APPLICABLE\n",
    "#\n",
    "#==============================================================================\n",
    "\n",
    "if (y.unique().any() == None):\n",
    "    print('\\n')\n",
    "    print('This appears to be new data. The prediction vector has been created '\n",
    "          'and is called \\'y_pred\\'. A comma-separated value copy has been '\n",
    "          'saved as \\'y_pred.csv\\'.')\n",
    "else:\n",
    "    #-----------------------------------------\n",
    "    # EVALUATE MODEL\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Classification report\n",
    "    cr = classification_report(y, y_pred)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = cm.diagonal().sum() / cm.sum()\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"CONFUSION MATRIX:\", sep=\"\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"CLASSIFICATION REPORT:\", sep=\"\")\n",
    "    print(cr)\n",
    "    print(\"\\n\")\n",
    "    print(\"ACCURACY: \", round(acc, 2), sep=\"\")\n",
    "    print('\\n')\n",
    "    print('The prediction vector has been created'\n",
    "          'and is called \\'y_pred\\'. A comma-separated value copy has been '\n",
    "          'saved as \\'y_pred.csv\\'.')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
